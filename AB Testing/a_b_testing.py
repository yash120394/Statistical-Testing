# -*- coding: utf-8 -*-
"""A/B Testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qcAmqoR1y7VRKzFXlagkvwPSXtrlmh0L
"""

import numpy as np
import pandas as pd
import scipy.stats as stats
import statsmodels.stats.api as sms
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.stats.power import TTestIndPower
from statsmodels.stats.proportion import proportions_ztest, proportion_confint

df = pd.read_csv('ab_data.csv')
df.head()

pd.crosstab(index=df['group'], columns=df['landing_page'])

df.groupby('group')['converted'].mean()

df_sub = df.drop_duplicates(subset='user_id', keep="first")
print("Number of rows of data:",len(df))
print("Number of rows of data after removing multiple users:",len(df_sub))

df_sub.groupby('group')['converted'].mean()

# Get least number of sample size
effect = sms.proportion_effectsize(0.12, 0.14)
alpha = 0.05
power = 0.8
analysis = TTestIndPower()
result = analysis.solve_power(effect, power=power, nobs1=None, ratio=1.0, alpha=alpha)
print('Sample Size: %.3f' % result)

import math
n = math.ceil(result)

#Sample for n control and n treatment group
df_control = df_sub.loc[df_sub['group'] == 'control']
df1 = df_control.sample(n=n)

df_treat = df_sub.loc[df_sub['group'] == 'treatment']
df2 = df_treat.sample(n=n)

df = pd.concat([df1,df2],axis=0)
df['group'].value_counts()

df.groupby('group')['converted'].agg([np.mean,lambda x: np.std(x, ddof=0),lambda x: stats.sem(x, ddof=0)])

# A/B Testing
count = np.array([np.sum(df1['converted']),np.sum(df2['converted'])])
nobs = np.array([len(df1),len(df2)])
stat, pval = proportions_ztest(count, nobs)

pval
# Hence not significant

stat

count

nobs

